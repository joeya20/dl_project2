{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a02285e6",
      "metadata": {
        "id": "a02285e6"
      },
      "source": [
        "# Starter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcc5329",
      "metadata": {
        "id": "bdcc5329"
      },
      "source": [
        "Install and import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
      "metadata": {
        "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in ./env/lib/python3.11/site-packages (4.51.1)\n",
            "Requirement already satisfied: datasets in ./env/lib/python3.11/site-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in ./env/lib/python3.11/site-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in ./env/lib/python3.11/site-packages (1.6.0)\n",
            "Requirement already satisfied: peft in ./env/lib/python3.11/site-packages (0.15.1)\n",
            "Requirement already satisfied: trl in ./env/lib/python3.11/site-packages (0.16.1)\n",
            "Requirement already satisfied: bitsandbytes in ./env/lib/python3.11/site-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in ./env/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./env/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./env/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./env/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./env/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in ./env/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in ./env/lib/python3.11/site-packages (from datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./env/lib/python3.11/site-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: psutil in ./env/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in ./env/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
            "Requirement already satisfied: rich in ./env/lib/python3.11/site-packages (from trl) (14.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env/lib/python3.11/site-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./env/lib/python3.11/site-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./env/lib/python3.11/site-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: nvidia-ml-py3 in ./env/lib/python3.11/site-packages (7.352.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: scikit-learn in ./env/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in ./env/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in ./env/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in ./env/lib/python3.11/site-packages (from scikit-learn) (2.2.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./env/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in ./env/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate accelerate peft trl bitsandbytes\n",
        "!pip install nvidia-ml-py3\n",
        "!pip install scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
      "metadata": {
        "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/joey/sp25-dl/project2/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-04-20 18:39:58.007684: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-20 18:39:58.126272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745188798.176943    2476 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745188798.191625    2476 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1745188798.303136    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745188798.303172    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745188798.303173    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745188798.303174    2476 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-20 18:39:58.316001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from datasets import load_dataset, Dataset, ClassLabel\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d6e377",
      "metadata": {
        "id": "59d6e377"
      },
      "source": [
        "## Load Tokenizer and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
      "metadata": {
        "id": "21f42747-f551-40a5-a95f-7affb1eba4a3"
      },
      "outputs": [],
      "source": [
        "base_model = 'roberta-base'\n",
        "\n",
        "dataset = load_dataset('ag_news', split='train')\n",
        "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
        "\n",
        "def preprocess(examples):\n",
        "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
      "metadata": {
        "id": "9e07f641-bec0-43a6-8c26-510d7642916a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of labels: 4\n",
            "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
          ]
        }
      ],
      "source": [
        "# Extract the number of classess and their names\n",
        "num_labels = dataset.features['label'].num_classes\n",
        "class_names = dataset.features[\"label\"].names\n",
        "print(f\"number of labels: {num_labels}\")\n",
        "print(f\"the labels: {class_names}\")\n",
        "\n",
        "# Create an id2label mapping\n",
        "# We will need this for our classifier.\n",
        "id2label = {i: label for i, label in enumerate(class_names)}\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0408894d",
      "metadata": {},
      "source": [
        "## Make train and eval split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7413430-be57-482b-856e-36bd4ba799df",
      "metadata": {
        "id": "e7413430-be57-482b-856e-36bd4ba799df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train samples: 118720\n",
            "Number of eval samples: 1280\n"
          ]
        }
      ],
      "source": [
        "# Split the original training set\n",
        "split_datasets = tokenized_dataset.train_test_split(test_size=1280, seed=42)\n",
        "train_dataset = split_datasets['train']\n",
        "eval_dataset = split_datasets['test']\n",
        "\n",
        "print(\"Number of train samples:\", len(train_dataset))\n",
        "print(\"Number of eval samples:\", len(eval_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12284b58",
      "metadata": {
        "id": "12284b58"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
      "metadata": {
        "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1"
      },
      "outputs": [],
      "source": [
        "# To track evaluation accuracy during training\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
      "metadata": {
        "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
        "    \"\"\"\n",
        "    Evaluate a PEFT model on a dataset.\n",
        "\n",
        "    Args:\n",
        "        inference_model: The model to evaluate.\n",
        "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
        "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
        "                         If False, only predictions will be returned.\n",
        "        batch_size (int): Batch size for inference.\n",
        "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
        "\n",
        "    Returns:\n",
        "        If labelled is True, returns a tuple (metrics, predictions)\n",
        "        If labelled is False, returns the predictions.\n",
        "    \"\"\"\n",
        "    # Create the DataLoader\n",
        "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    inference_model.to(device)\n",
        "    inference_model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    if labelled:\n",
        "        metric = evaluate.load('accuracy')\n",
        "\n",
        "    # Loop over the DataLoader\n",
        "    for batch in tqdm(eval_dataloader):\n",
        "        # Move each tensor in the batch to the device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = inference_model(**batch)\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        all_predictions.append(predictions.cpu())\n",
        "\n",
        "        if labelled:\n",
        "            # Expecting that labels are provided under the \"labels\" key.\n",
        "            references = batch[\"labels\"]\n",
        "            metric.add_batch(\n",
        "                predictions=predictions.cpu().numpy(),\n",
        "                references=references.cpu().numpy()\n",
        "            )\n",
        "\n",
        "    # Concatenate predictions from all batches\n",
        "    all_predictions = torch.cat(all_predictions, dim=0)\n",
        "\n",
        "    if labelled:\n",
        "        eval_metric = metric.compute()\n",
        "        print(\"Evaluation Metric:\", eval_metric)\n",
        "        return eval_metric, all_predictions\n",
        "    else:\n",
        "        return all_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652452e3",
      "metadata": {
        "id": "652452e3"
      },
      "source": [
        "## Design Space Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9342bc22",
      "metadata": {},
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7750e71f",
      "metadata": {},
      "outputs": [],
      "source": [
        "output_base_dir = \"dse_results\" # base directory for all DSE runs\n",
        "os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "# hyperparameter ranges for DSE\n",
        "lora_ranks = [4, 5, 6, 7] \n",
        "lora_alpha_scaling = [1, 2, 3, 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7113c425",
      "metadata": {},
      "source": [
        "\n",
        "### Design Space Exploration Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876",
      "metadata": {
        "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run: rank_4_alpha_4 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=4, alpha=4\n",
            "PEFT Model Configured:\n",
            "trainable params: 814,852 || all params: 125,463,560 || trainable%: 0.6495\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:48, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.398700</td>\n",
              "      <td>1.385969</td>\n",
              "      <td>0.247656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379900</td>\n",
              "      <td>1.375162</td>\n",
              "      <td>0.247656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.372000</td>\n",
              "      <td>1.365314</td>\n",
              "      <td>0.428906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.361000</td>\n",
              "      <td>1.354804</td>\n",
              "      <td>0.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.350900</td>\n",
              "      <td>1.341707</td>\n",
              "      <td>0.653906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.328100</td>\n",
              "      <td>1.321327</td>\n",
              "      <td>0.821875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.303400</td>\n",
              "      <td>1.296508</td>\n",
              "      <td>0.790625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.279600</td>\n",
              "      <td>1.261755</td>\n",
              "      <td>0.854688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.237500</td>\n",
              "      <td>1.215027</td>\n",
              "      <td>0.861719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.178300</td>\n",
              "      <td>1.144910</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.098600</td>\n",
              "      <td>1.054453</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.001300</td>\n",
              "      <td>0.948648</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.896300</td>\n",
              "      <td>0.836082</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.781800</td>\n",
              "      <td>0.725088</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.711000</td>\n",
              "      <td>0.639361</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.644800</td>\n",
              "      <td>0.578818</td>\n",
              "      <td>0.878125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.538808</td>\n",
              "      <td>0.879687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.573800</td>\n",
              "      <td>0.515655</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.547100</td>\n",
              "      <td>0.503312</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.532900</td>\n",
              "      <td>0.499566</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88125}\n",
            "Run rank_4_alpha_4 completed. Accuracy: 0.8812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Run: rank_4_alpha_8 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=4, alpha=8\n",
            "PEFT Model Configured:\n",
            "trainable params: 814,852 || all params: 125,463,560 || trainable%: 0.6495\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.394000</td>\n",
              "      <td>1.382361</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379200</td>\n",
              "      <td>1.373064</td>\n",
              "      <td>0.296875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.371100</td>\n",
              "      <td>1.363087</td>\n",
              "      <td>0.678125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.357800</td>\n",
              "      <td>1.348700</td>\n",
              "      <td>0.739844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.336900</td>\n",
              "      <td>1.325458</td>\n",
              "      <td>0.753125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.300300</td>\n",
              "      <td>1.280290</td>\n",
              "      <td>0.856250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.232700</td>\n",
              "      <td>1.194090</td>\n",
              "      <td>0.849219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.109300</td>\n",
              "      <td>1.015854</td>\n",
              "      <td>0.871094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.895000</td>\n",
              "      <td>0.738917</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.665700</td>\n",
              "      <td>0.543590</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.546800</td>\n",
              "      <td>0.460666</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.473300</td>\n",
              "      <td>0.413007</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.442500</td>\n",
              "      <td>0.391228</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.386500</td>\n",
              "      <td>0.377331</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.409000</td>\n",
              "      <td>0.370552</td>\n",
              "      <td>0.882031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.390400</td>\n",
              "      <td>0.364129</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.387700</td>\n",
              "      <td>0.361453</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.375700</td>\n",
              "      <td>0.359846</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.379700</td>\n",
              "      <td>0.359086</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.374600</td>\n",
              "      <td>0.358987</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88515625}\n",
            "Run rank_4_alpha_8 completed. Accuracy: 0.8852\n",
            "\n",
            "--- Starting Run: rank_4_alpha_12 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=4, alpha=12\n",
            "PEFT Model Configured:\n",
            "trainable params: 814,852 || all params: 125,463,560 || trainable%: 0.6495\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393900</td>\n",
              "      <td>1.382194</td>\n",
              "      <td>0.291406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378800</td>\n",
              "      <td>1.372128</td>\n",
              "      <td>0.294531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.369200</td>\n",
              "      <td>1.359791</td>\n",
              "      <td>0.710156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.351100</td>\n",
              "      <td>1.337805</td>\n",
              "      <td>0.771094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.314500</td>\n",
              "      <td>1.289432</td>\n",
              "      <td>0.803125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.223100</td>\n",
              "      <td>1.147522</td>\n",
              "      <td>0.864844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.995900</td>\n",
              "      <td>0.805436</td>\n",
              "      <td>0.860938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.703100</td>\n",
              "      <td>0.543149</td>\n",
              "      <td>0.882031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.536200</td>\n",
              "      <td>0.442370</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.445700</td>\n",
              "      <td>0.398419</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.418000</td>\n",
              "      <td>0.385278</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.395100</td>\n",
              "      <td>0.365621</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.387300</td>\n",
              "      <td>0.360088</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.339200</td>\n",
              "      <td>0.355334</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.372700</td>\n",
              "      <td>0.353408</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.357800</td>\n",
              "      <td>0.349352</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.363300</td>\n",
              "      <td>0.349098</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.349300</td>\n",
              "      <td>0.348720</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.348825</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.353200</td>\n",
              "      <td>0.349017</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.8859375}\n",
            "Run rank_4_alpha_12 completed. Accuracy: 0.8859\n",
            "\n",
            "--- Starting Run: rank_4_alpha_16 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=4, alpha=16\n",
            "PEFT Model Configured:\n",
            "trainable params: 814,852 || all params: 125,463,560 || trainable%: 0.6495\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393800</td>\n",
              "      <td>1.382059</td>\n",
              "      <td>0.292187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378300</td>\n",
              "      <td>1.371160</td>\n",
              "      <td>0.309375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.367000</td>\n",
              "      <td>1.356177</td>\n",
              "      <td>0.731250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.342700</td>\n",
              "      <td>1.323363</td>\n",
              "      <td>0.799219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.277500</td>\n",
              "      <td>1.220430</td>\n",
              "      <td>0.833594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.069300</td>\n",
              "      <td>0.857281</td>\n",
              "      <td>0.869531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.723900</td>\n",
              "      <td>0.550895</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.538600</td>\n",
              "      <td>0.438915</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.453900</td>\n",
              "      <td>0.397087</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.400700</td>\n",
              "      <td>0.375054</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.388500</td>\n",
              "      <td>0.371648</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.375700</td>\n",
              "      <td>0.355784</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.372300</td>\n",
              "      <td>0.353224</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.324800</td>\n",
              "      <td>0.349969</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.361400</td>\n",
              "      <td>0.349097</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.348500</td>\n",
              "      <td>0.345133</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.355800</td>\n",
              "      <td>0.345766</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.341100</td>\n",
              "      <td>0.345673</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>0.346122</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.346423</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88671875}\n",
            "Run rank_4_alpha_16 completed. Accuracy: 0.8867\n",
            "\n",
            "--- Starting Run: rank_5_alpha_5 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=5, alpha=5\n",
            "PEFT Model Configured:\n",
            "trainable params: 870,148 || all params: 125,518,856 || trainable%: 0.6932\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.394100</td>\n",
              "      <td>1.382536</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379400</td>\n",
              "      <td>1.373573</td>\n",
              "      <td>0.283594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.372200</td>\n",
              "      <td>1.364794</td>\n",
              "      <td>0.653125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.361400</td>\n",
              "      <td>1.353891</td>\n",
              "      <td>0.725781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.347000</td>\n",
              "      <td>1.339573</td>\n",
              "      <td>0.729688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.325700</td>\n",
              "      <td>1.316870</td>\n",
              "      <td>0.842969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.296800</td>\n",
              "      <td>1.285397</td>\n",
              "      <td>0.826562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.259300</td>\n",
              "      <td>1.237168</td>\n",
              "      <td>0.863281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.195900</td>\n",
              "      <td>1.162220</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.094000</td>\n",
              "      <td>1.039644</td>\n",
              "      <td>0.876563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.962400</td>\n",
              "      <td>0.874728</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.799300</td>\n",
              "      <td>0.701885</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.674600</td>\n",
              "      <td>0.576754</td>\n",
              "      <td>0.876563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.557400</td>\n",
              "      <td>0.500222</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.533500</td>\n",
              "      <td>0.460998</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.494900</td>\n",
              "      <td>0.436198</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.469200</td>\n",
              "      <td>0.421910</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.457300</td>\n",
              "      <td>0.413492</td>\n",
              "      <td>0.879687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.452300</td>\n",
              "      <td>0.409055</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.439800</td>\n",
              "      <td>0.407792</td>\n",
              "      <td>0.878125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.878125}\n",
            "Run rank_5_alpha_5 completed. Accuracy: 0.8781\n",
            "\n",
            "--- Starting Run: rank_5_alpha_10 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=5, alpha=10\n",
            "PEFT Model Configured:\n",
            "trainable params: 870,148 || all params: 125,518,856 || trainable%: 0.6932\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.394000</td>\n",
              "      <td>1.382374</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379000</td>\n",
              "      <td>1.372773</td>\n",
              "      <td>0.300781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.370400</td>\n",
              "      <td>1.361708</td>\n",
              "      <td>0.684375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.354700</td>\n",
              "      <td>1.343669</td>\n",
              "      <td>0.759375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.326300</td>\n",
              "      <td>1.309173</td>\n",
              "      <td>0.784375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.265700</td>\n",
              "      <td>1.221551</td>\n",
              "      <td>0.867188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.121300</td>\n",
              "      <td>1.004559</td>\n",
              "      <td>0.863281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.857100</td>\n",
              "      <td>0.670044</td>\n",
              "      <td>0.878125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.623500</td>\n",
              "      <td>0.496726</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.491000</td>\n",
              "      <td>0.424245</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.443100</td>\n",
              "      <td>0.399654</td>\n",
              "      <td>0.875781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.411500</td>\n",
              "      <td>0.374867</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.399000</td>\n",
              "      <td>0.366323</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>0.359968</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.380800</td>\n",
              "      <td>0.356968</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.365500</td>\n",
              "      <td>0.352623</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.368400</td>\n",
              "      <td>0.351753</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.355300</td>\n",
              "      <td>0.351079</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.360300</td>\n",
              "      <td>0.350977</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.356800</td>\n",
              "      <td>0.351093</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.8859375}\n",
            "Run rank_5_alpha_10 completed. Accuracy: 0.8859\n",
            "\n",
            "--- Starting Run: rank_5_alpha_15 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=5, alpha=15\n",
            "PEFT Model Configured:\n",
            "trainable params: 870,148 || all params: 125,518,856 || trainable%: 0.6932\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393900</td>\n",
              "      <td>1.382201</td>\n",
              "      <td>0.289844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378500</td>\n",
              "      <td>1.371769</td>\n",
              "      <td>0.308594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.368000</td>\n",
              "      <td>1.357667</td>\n",
              "      <td>0.713281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.345600</td>\n",
              "      <td>1.328254</td>\n",
              "      <td>0.791406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.287500</td>\n",
              "      <td>1.238199</td>\n",
              "      <td>0.820312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.101900</td>\n",
              "      <td>0.907912</td>\n",
              "      <td>0.868750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.752600</td>\n",
              "      <td>0.565179</td>\n",
              "      <td>0.874219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.542900</td>\n",
              "      <td>0.441495</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.453800</td>\n",
              "      <td>0.396510</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.399200</td>\n",
              "      <td>0.374239</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.384500</td>\n",
              "      <td>0.370556</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.374100</td>\n",
              "      <td>0.354662</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.370600</td>\n",
              "      <td>0.352106</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.323900</td>\n",
              "      <td>0.348657</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.359100</td>\n",
              "      <td>0.347489</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.346900</td>\n",
              "      <td>0.343746</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.354600</td>\n",
              "      <td>0.344245</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.344171</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.341800</td>\n",
              "      <td>0.344601</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.342600</td>\n",
              "      <td>0.344878</td>\n",
              "      <td>0.892188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88828125}\n",
            "Run rank_5_alpha_15 completed. Accuracy: 0.8883\n",
            "\n",
            "--- Starting Run: rank_5_alpha_20 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=5, alpha=20\n",
            "PEFT Model Configured:\n",
            "trainable params: 870,148 || all params: 125,518,856 || trainable%: 0.6932\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393800</td>\n",
              "      <td>1.382071</td>\n",
              "      <td>0.292969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378100</td>\n",
              "      <td>1.370824</td>\n",
              "      <td>0.317969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.365600</td>\n",
              "      <td>1.353085</td>\n",
              "      <td>0.735156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.332800</td>\n",
              "      <td>1.302333</td>\n",
              "      <td>0.815625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.207600</td>\n",
              "      <td>1.063502</td>\n",
              "      <td>0.835156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.848500</td>\n",
              "      <td>0.611960</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.553100</td>\n",
              "      <td>0.454211</td>\n",
              "      <td>0.874219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.398928</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.413500</td>\n",
              "      <td>0.376445</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.375400</td>\n",
              "      <td>0.363024</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.365900</td>\n",
              "      <td>0.363156</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.361600</td>\n",
              "      <td>0.348716</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.347948</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.314200</td>\n",
              "      <td>0.344864</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.351100</td>\n",
              "      <td>0.344176</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.340462</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.341583</td>\n",
              "      <td>0.892969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.332600</td>\n",
              "      <td>0.341732</td>\n",
              "      <td>0.892188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.333200</td>\n",
              "      <td>0.342350</td>\n",
              "      <td>0.892188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.335200</td>\n",
              "      <td>0.342689</td>\n",
              "      <td>0.892188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88984375}\n",
            "Run rank_5_alpha_20 completed. Accuracy: 0.8898\n",
            "\n",
            "--- Starting Run: rank_6_alpha_6 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=6, alpha=6\n",
            "PEFT Model Configured:\n",
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:54, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.394100</td>\n",
              "      <td>1.382472</td>\n",
              "      <td>0.286719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379300</td>\n",
              "      <td>1.373308</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.371700</td>\n",
              "      <td>1.364031</td>\n",
              "      <td>0.665625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.359900</td>\n",
              "      <td>1.351794</td>\n",
              "      <td>0.731250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.343200</td>\n",
              "      <td>1.334289</td>\n",
              "      <td>0.740625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.316700</td>\n",
              "      <td>1.304460</td>\n",
              "      <td>0.853125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.276700</td>\n",
              "      <td>1.258208</td>\n",
              "      <td>0.838281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.215600</td>\n",
              "      <td>1.177003</td>\n",
              "      <td>0.865625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.103700</td>\n",
              "      <td>1.036199</td>\n",
              "      <td>0.868750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.927100</td>\n",
              "      <td>0.810609</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.733100</td>\n",
              "      <td>0.610494</td>\n",
              "      <td>0.874219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.588200</td>\n",
              "      <td>0.499216</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.516400</td>\n",
              "      <td>0.444670</td>\n",
              "      <td>0.879687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.441600</td>\n",
              "      <td>0.413265</td>\n",
              "      <td>0.878125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.449900</td>\n",
              "      <td>0.397772</td>\n",
              "      <td>0.879687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.426200</td>\n",
              "      <td>0.386600</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.414500</td>\n",
              "      <td>0.380718</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.403300</td>\n",
              "      <td>0.377236</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.405400</td>\n",
              "      <td>0.375433</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.396300</td>\n",
              "      <td>0.375006</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.884375}\n",
            "Run rank_6_alpha_6 completed. Accuracy: 0.8844\n",
            "\n",
            "--- Starting Run: rank_6_alpha_12 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=6, alpha=12\n",
            "PEFT Model Configured:\n",
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393900</td>\n",
              "      <td>1.382226</td>\n",
              "      <td>0.290625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378800</td>\n",
              "      <td>1.372229</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.369300</td>\n",
              "      <td>1.360016</td>\n",
              "      <td>0.699219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.351200</td>\n",
              "      <td>1.338032</td>\n",
              "      <td>0.775781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.313600</td>\n",
              "      <td>1.287932</td>\n",
              "      <td>0.802344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.216600</td>\n",
              "      <td>1.133754</td>\n",
              "      <td>0.867969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.972500</td>\n",
              "      <td>0.771528</td>\n",
              "      <td>0.860938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.673100</td>\n",
              "      <td>0.520115</td>\n",
              "      <td>0.878906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.516600</td>\n",
              "      <td>0.430560</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.432000</td>\n",
              "      <td>0.391744</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.407200</td>\n",
              "      <td>0.382132</td>\n",
              "      <td>0.876563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.387000</td>\n",
              "      <td>0.362767</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.381200</td>\n",
              "      <td>0.358087</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.334800</td>\n",
              "      <td>0.353937</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.367900</td>\n",
              "      <td>0.352204</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.353700</td>\n",
              "      <td>0.348558</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.359500</td>\n",
              "      <td>0.348417</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.342900</td>\n",
              "      <td>0.348178</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.348700</td>\n",
              "      <td>0.348429</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.347700</td>\n",
              "      <td>0.348627</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.8890625}\n",
            "Run rank_6_alpha_12 completed. Accuracy: 0.8891\n",
            "\n",
            "--- Starting Run: rank_6_alpha_18 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=6, alpha=18\n",
            "PEFT Model Configured:\n",
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393700</td>\n",
              "      <td>1.382016</td>\n",
              "      <td>0.295312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378100</td>\n",
              "      <td>1.370759</td>\n",
              "      <td>0.324219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.365800</td>\n",
              "      <td>1.353727</td>\n",
              "      <td>0.740625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.335800</td>\n",
              "      <td>1.310153</td>\n",
              "      <td>0.813281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.233300</td>\n",
              "      <td>1.124413</td>\n",
              "      <td>0.835938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.911300</td>\n",
              "      <td>0.660174</td>\n",
              "      <td>0.878125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.581100</td>\n",
              "      <td>0.467990</td>\n",
              "      <td>0.875781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.472400</td>\n",
              "      <td>0.404792</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.418400</td>\n",
              "      <td>0.379733</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.376300</td>\n",
              "      <td>0.365393</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.367300</td>\n",
              "      <td>0.365453</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.361100</td>\n",
              "      <td>0.350623</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.361100</td>\n",
              "      <td>0.349348</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.315400</td>\n",
              "      <td>0.346586</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.346004</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.339300</td>\n",
              "      <td>0.342418</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.350200</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.330400</td>\n",
              "      <td>0.343667</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.332600</td>\n",
              "      <td>0.344348</td>\n",
              "      <td>0.894531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.335600</td>\n",
              "      <td>0.344713</td>\n",
              "      <td>0.894531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88984375}\n",
            "Run rank_6_alpha_18 completed. Accuracy: 0.8898\n",
            "\n",
            "--- Starting Run: rank_6_alpha_24 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=6, alpha=24\n",
            "PEFT Model Configured:\n",
            "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:54, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393600</td>\n",
              "      <td>1.381789</td>\n",
              "      <td>0.304688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.377500</td>\n",
              "      <td>1.369642</td>\n",
              "      <td>0.332813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.362400</td>\n",
              "      <td>1.346985</td>\n",
              "      <td>0.764062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.312700</td>\n",
              "      <td>1.256881</td>\n",
              "      <td>0.835938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.081500</td>\n",
              "      <td>0.826863</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.500469</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.476400</td>\n",
              "      <td>0.419518</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.431200</td>\n",
              "      <td>0.383378</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.394500</td>\n",
              "      <td>0.368124</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.359700</td>\n",
              "      <td>0.357943</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.354400</td>\n",
              "      <td>0.360655</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.351400</td>\n",
              "      <td>0.346052</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.353200</td>\n",
              "      <td>0.346400</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.308300</td>\n",
              "      <td>0.343451</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>0.343013</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.332600</td>\n",
              "      <td>0.339372</td>\n",
              "      <td>0.895312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.346200</td>\n",
              "      <td>0.341098</td>\n",
              "      <td>0.895312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.324800</td>\n",
              "      <td>0.341489</td>\n",
              "      <td>0.894531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.324100</td>\n",
              "      <td>0.342356</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.342785</td>\n",
              "      <td>0.892969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.89375}\n",
            "Run rank_6_alpha_24 completed. Accuracy: 0.8938\n",
            "\n",
            "--- Starting Run: rank_7_alpha_7 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=7, alpha=7\n",
            "PEFT Model Configured:\n",
            "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.394100</td>\n",
              "      <td>1.382395</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379200</td>\n",
              "      <td>1.373016</td>\n",
              "      <td>0.289844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.371000</td>\n",
              "      <td>1.362894</td>\n",
              "      <td>0.680469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.357900</td>\n",
              "      <td>1.348767</td>\n",
              "      <td>0.743750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.337900</td>\n",
              "      <td>1.326946</td>\n",
              "      <td>0.758594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.304300</td>\n",
              "      <td>1.286667</td>\n",
              "      <td>0.853906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.246500</td>\n",
              "      <td>1.214800</td>\n",
              "      <td>0.851562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.143500</td>\n",
              "      <td>1.070203</td>\n",
              "      <td>0.871875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.956600</td>\n",
              "      <td>0.822199</td>\n",
              "      <td>0.867969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.723500</td>\n",
              "      <td>0.592419</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.572700</td>\n",
              "      <td>0.481945</td>\n",
              "      <td>0.877344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.487200</td>\n",
              "      <td>0.424279</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.449500</td>\n",
              "      <td>0.398066</td>\n",
              "      <td>0.881250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.390900</td>\n",
              "      <td>0.382303</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.412400</td>\n",
              "      <td>0.374818</td>\n",
              "      <td>0.882031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.392500</td>\n",
              "      <td>0.368110</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.389100</td>\n",
              "      <td>0.365228</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>0.363538</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.381000</td>\n",
              "      <td>0.362777</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.375300</td>\n",
              "      <td>0.362669</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88359375}\n",
            "Run rank_7_alpha_7 completed. Accuracy: 0.8836\n",
            "\n",
            "--- Starting Run: rank_7_alpha_14 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=7, alpha=14\n",
            "PEFT Model Configured:\n",
            "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:50, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393800</td>\n",
              "      <td>1.382114</td>\n",
              "      <td>0.290625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.378400</td>\n",
              "      <td>1.371282</td>\n",
              "      <td>0.306250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.367200</td>\n",
              "      <td>1.356394</td>\n",
              "      <td>0.732812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.343400</td>\n",
              "      <td>1.325195</td>\n",
              "      <td>0.805469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.283800</td>\n",
              "      <td>1.234934</td>\n",
              "      <td>0.830469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.095800</td>\n",
              "      <td>0.902325</td>\n",
              "      <td>0.871094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.750200</td>\n",
              "      <td>0.563787</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.542700</td>\n",
              "      <td>0.440475</td>\n",
              "      <td>0.882812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.452700</td>\n",
              "      <td>0.397204</td>\n",
              "      <td>0.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.399000</td>\n",
              "      <td>0.376267</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.386400</td>\n",
              "      <td>0.372607</td>\n",
              "      <td>0.879687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.375200</td>\n",
              "      <td>0.357677</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.372100</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.325100</td>\n",
              "      <td>0.352283</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.361400</td>\n",
              "      <td>0.351584</td>\n",
              "      <td>0.885938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.347200</td>\n",
              "      <td>0.347734</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.355700</td>\n",
              "      <td>0.348201</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.341500</td>\n",
              "      <td>0.348234</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.341700</td>\n",
              "      <td>0.348694</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.344700</td>\n",
              "      <td>0.348991</td>\n",
              "      <td>0.887500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.8859375}\n",
            "Run rank_7_alpha_14 completed. Accuracy: 0.8859\n",
            "\n",
            "--- Starting Run: rank_7_alpha_21 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=7, alpha=21\n",
            "PEFT Model Configured:\n",
            "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393600</td>\n",
              "      <td>1.381833</td>\n",
              "      <td>0.296875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.377500</td>\n",
              "      <td>1.369431</td>\n",
              "      <td>0.332813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.362600</td>\n",
              "      <td>1.347631</td>\n",
              "      <td>0.767969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.319600</td>\n",
              "      <td>1.276217</td>\n",
              "      <td>0.831250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.134800</td>\n",
              "      <td>0.923292</td>\n",
              "      <td>0.846094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.731600</td>\n",
              "      <td>0.531543</td>\n",
              "      <td>0.873437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.497300</td>\n",
              "      <td>0.429075</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.441200</td>\n",
              "      <td>0.389219</td>\n",
              "      <td>0.884375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.401300</td>\n",
              "      <td>0.372620</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>0.362410</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.361000</td>\n",
              "      <td>0.363652</td>\n",
              "      <td>0.882031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.357800</td>\n",
              "      <td>0.349688</td>\n",
              "      <td>0.889062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.359100</td>\n",
              "      <td>0.348653</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>0.346694</td>\n",
              "      <td>0.888281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.350200</td>\n",
              "      <td>0.346549</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.336400</td>\n",
              "      <td>0.342603</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>0.343833</td>\n",
              "      <td>0.892969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.332300</td>\n",
              "      <td>0.344025</td>\n",
              "      <td>0.891406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.328400</td>\n",
              "      <td>0.344808</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.334800</td>\n",
              "      <td>0.345181</td>\n",
              "      <td>0.889844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.88984375}\n",
            "Run rank_7_alpha_21 completed. Accuracy: 0.8898\n",
            "\n",
            "--- Starting Run: rank_7_alpha_28 ---\n",
            "Loading base model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring LoRA with r=7, alpha=28\n",
            "PEFT Model Configured:\n",
            "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n",
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 30:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.393400</td>\n",
              "      <td>1.381527</td>\n",
              "      <td>0.310937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.376600</td>\n",
              "      <td>1.367744</td>\n",
              "      <td>0.342187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.357300</td>\n",
              "      <td>1.336867</td>\n",
              "      <td>0.814844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.277500</td>\n",
              "      <td>1.169184</td>\n",
              "      <td>0.840625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.941500</td>\n",
              "      <td>0.665824</td>\n",
              "      <td>0.868750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.568900</td>\n",
              "      <td>0.452165</td>\n",
              "      <td>0.876563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.402947</td>\n",
              "      <td>0.874219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.415100</td>\n",
              "      <td>0.375679</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.384600</td>\n",
              "      <td>0.364113</td>\n",
              "      <td>0.883594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.353000</td>\n",
              "      <td>0.355569</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.350300</td>\n",
              "      <td>0.358791</td>\n",
              "      <td>0.885156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.348600</td>\n",
              "      <td>0.344787</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.351400</td>\n",
              "      <td>0.344738</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.306200</td>\n",
              "      <td>0.342644</td>\n",
              "      <td>0.892969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.343000</td>\n",
              "      <td>0.342547</td>\n",
              "      <td>0.892969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>0.338713</td>\n",
              "      <td>0.892188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.340521</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.325500</td>\n",
              "      <td>0.340841</td>\n",
              "      <td>0.895312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.320600</td>\n",
              "      <td>0.341744</td>\n",
              "      <td>0.896094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.328800</td>\n",
              "      <td>0.342202</td>\n",
              "      <td>0.893750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Evaluating model on evaluation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.89296875}\n",
            "Run rank_7_alpha_28 completed. Accuracy: 0.8930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import gc # Garbage collector for potentially clearing GPU memory\n",
        "\n",
        "results = []\n",
        "\n",
        "for rank in lora_ranks:\n",
        "    for alpha_scale in lora_alpha_scaling:\n",
        "        alpha = rank * alpha_scale\n",
        "        run_name = f\"rank_{rank}_alpha_{alpha}\"\n",
        "        print(f\"\\n--- Starting Run: {run_name} ---\")\n",
        "\n",
        "        # Define output directory for this specific run\n",
        "        current_output_dir = os.path.join(output_base_dir, run_name)\n",
        "        os.makedirs(current_output_dir, exist_ok=True)\n",
        "\n",
        "        # 1. Load Base Model (Load fresh for each run)\n",
        "        print(\"Loading base model...\")\n",
        "\n",
        "        model = RobertaForSequenceClassification.from_pretrained(\n",
        "            base_model,\n",
        "            id2label=id2label)\n",
        "\n",
        "        # Move model to GPU if possible\n",
        "        if torch.cuda.is_available():\n",
        "            model.to('cuda')\n",
        "\n",
        "        # Configure LoRA\n",
        "        print(f\"Configuring LoRA with r={rank}, alpha={alpha}\")\n",
        "        peft_config = LoraConfig(\n",
        "            r=rank,  # LoRA rank\n",
        "            lora_alpha=alpha,  # Alpha parameter for scaling\n",
        "            lora_dropout=0.2, # Dropout probability for LoRA layers\n",
        "            target_modules=[\"query\", \"key\", \"value\"], # Apply LoRA to these layers\n",
        "            bias=\"none\",  # Don't train bias parameters\n",
        "            task_type=\"SEQ_CLS\", # Specify the task type\n",
        "        )\n",
        "\n",
        "        peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "        print(\"PEFT Model Configured:\")\n",
        "        peft_model.print_trainable_parameters()\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=current_output_dir,\n",
        "            report_to=None,\n",
        "            eval_strategy=\"steps\",\n",
        "            logging_steps=100,\n",
        "            learning_rate=1e-5,\n",
        "            max_steps=2000,\n",
        "            num_train_epochs=1,\n",
        "            use_cpu=False,\n",
        "            dataloader_num_workers=4,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=64, # or 128\n",
        "            optim=\"adamw_torch\",\n",
        "            gradient_checkpointing=False,\n",
        "            gradient_checkpointing_kwargs={'use_reentrant': True},\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=peft_model,\n",
        "            args=training_args,\n",
        "            compute_metrics=compute_metrics,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "\n",
        "        # 6. Train the model\n",
        "        print(\"Starting training...\")\n",
        "        try:\n",
        "            train_result = trainer.train()\n",
        "            print(\"Training finished.\")\n",
        "            trainer.save_model()\n",
        "\n",
        "            # 7. Evaluate the model after training\n",
        "            print(\"Evaluating model on evaluation set...\")\n",
        "            eval_metrics, _ = evaluate_model(\n",
        "                peft_model,\n",
        "                eval_dataset,\n",
        "                labelled=True,\n",
        "                batch_size=training_args.per_device_eval_batch_size,\n",
        "                data_collator=data_collator\n",
        "            )\n",
        "            final_accuracy = eval_metrics.get('accuracy', float('nan'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!!! ERROR during training/evaluation for {run_name}: {e}\")\n",
        "            final_accuracy = float('nan')  # Record failure\n",
        "\n",
        "        # 8. Store results\n",
        "        results.append({\n",
        "            \"lora_rank\": rank,\n",
        "            \"lora_alpha\": alpha,\n",
        "            \"accuracy\": final_accuracy,\n",
        "            \"output_dir\": current_output_dir\n",
        "        })\n",
        "        print(f\"Run {run_name} completed. Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "        # 9. Clean up memory (Important!)\n",
        "        del model\n",
        "        del peft_model\n",
        "        del trainer\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6ffef8",
      "metadata": {},
      "source": [
        "## Post-DSE Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "19906cb4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    lora_rank  lora_alpha  accuracy                   output_dir\n",
            "11          6          24  0.893750  dse_results/rank_6_alpha_24\n",
            "15          7          28  0.892969  dse_results/rank_7_alpha_28\n",
            "7           5          20  0.889844  dse_results/rank_5_alpha_20\n",
            "14          7          21  0.889844  dse_results/rank_7_alpha_21\n",
            "10          6          18  0.889844  dse_results/rank_6_alpha_18\n",
            "9           6          12  0.889062  dse_results/rank_6_alpha_12\n",
            "6           5          15  0.888281  dse_results/rank_5_alpha_15\n",
            "3           4          16  0.886719  dse_results/rank_4_alpha_16\n",
            "2           4          12  0.885938  dse_results/rank_4_alpha_12\n",
            "13          7          14  0.885938  dse_results/rank_7_alpha_14\n",
            "5           5          10  0.885938  dse_results/rank_5_alpha_10\n",
            "1           4           8  0.885156   dse_results/rank_4_alpha_8\n",
            "8           6           6  0.884375   dse_results/rank_6_alpha_6\n",
            "12          7           7  0.883594   dse_results/rank_7_alpha_7\n",
            "0           4           4  0.881250   dse_results/rank_4_alpha_4\n",
            "4           5           5  0.878125   dse_results/rank_5_alpha_5\n",
            "\n",
            "Full DSE results saved to: dse_results/dse_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# Convert results to DataFrame for easy viewing/sorting\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"accuracy\", ascending=False)\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "# Save results to CSV\n",
        "results_csv_path = os.path.join(output_base_dir, \"dse_summary.csv\")\n",
        "results_df.to_csv(results_csv_path, index=False)\n",
        "print(f\"\\nFull DSE results saved to: {results_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203",
      "metadata": {
        "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203"
      },
      "source": [
        "### Run Inference on unlabelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1b33f4a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model from: dse_results/rank_4_alpha_4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load best model from DSE\n",
        "model_path = \"dse_results/rank_4_alpha_4\"\n",
        "\n",
        "print(f\"Loading best model from: {model_path}\")\n",
        "# Load the base model again\n",
        "base_inference_model = RobertaForSequenceClassification.from_pretrained(\n",
        "    base_model,\n",
        "    id2label=id2label,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "# Load the PEFT adapter\n",
        "inference_model = PeftModel.from_pretrained(base_inference_model, model_path)\n",
        "inference_model.merge_and_unload() # Optional: Merge adapter weights for potentially faster inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e1635d09",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.86875}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as data_utils\n",
        "\n",
        "# Check evaluation accuracy\n",
        "testset = load_dataset('ag_news', split='test')\n",
        "\n",
        "tokenized_testset = testset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
        "tokenized_testset = tokenized_testset.rename_column(\"label\", \"labels\")\n",
        "indices = torch.arange(1280)\n",
        "tokenized_testset_sub = data_utils.Subset(tokenized_testset, indices)\n",
        "\n",
        "_, _ = evaluate_model(inference_model, tokenized_testset_sub, True, 64, data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7",
      "metadata": {
        "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 8000/8000 [00:02<00:00, 3234.79 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 8000\n",
              "})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load your unlabelled data\n",
        "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
        "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "unlabelled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e60991d3-38b1-4657-8854-408ce66f6b84",
      "metadata": {
        "id": "e60991d3-38b1-4657-8854-408ce66f6b84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:40<00:00,  9.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference complete. Predictions saved to inference_output.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run inference and save predictions\n",
        "preds = evaluate_model(inference_model, test_dataset, False, 8, data_collator)\n",
        "df_output = pd.DataFrame({\n",
        "    'ID': range(len(preds)),\n",
        "    'Label': preds.numpy()  # or preds.tolist()\n",
        "})\n",
        "df_output.to_csv(os.path.join(model_path,\"inference_output.csv\"), index=False)\n",
        "print(\"Inference complete. Predictions saved to inference_output.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cadcf21a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "results_csv_path = os.path.join(\"dse_results_do0.2\", \"dse_summary.csv\")\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# Add lora_alpha_multiplier column\n",
        "df[\"lora_alpha_multiplier\"] = df[\"lora_alpha\"] // df[\"lora_rank\"]\n",
        "\n",
        "# Pivot the data\n",
        "pivot = df.pivot(index=\"lora_rank\", columns=\"lora_alpha_multiplier\", values=\"accuracy\")\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(pivot, annot=True, fmt=\".4f\", cmap=\"viridis\", cbar_kws={'label': 'Accuracy'})\n",
        "plt.title(\"Accuracy Heatmap by LoRA Rank and Alpha Multiplier\")\n",
        "plt.xlabel(r\"LoRA Alpha Multiplier ($\\alpha$/rank)\")\n",
        "plt.ylabel(\"LoRA Rank\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('dse_heatmap.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac045506",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model from: dse_results_do0.2/rank_6_alpha_6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:21<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metric: {'accuracy': 0.884375}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load best model from DSE\n",
        "model_path = \"dse_results_do0.2/rank_6_alpha_6\"\n",
        "\n",
        "print(f\"Loading best model from: {model_path}\")\n",
        "# Load the base model again\n",
        "base_inference_model = RobertaForSequenceClassification.from_pretrained(\n",
        "    base_model,\n",
        "    id2label=id2label,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "# Load the PEFT adapter\n",
        "inference_model = PeftModel.from_pretrained(base_inference_model, model_path)\n",
        "inference_model.merge_and_unload() # Optional: Merge adapter weights for potentially faster inference\n",
        "\n",
        "eval_metric, all_predictions = evaluate_model(inference_model, eval_dataset, labelled=True, batch_size=16, data_collator=data_collator)\n",
        "true_labels = eval_dataset[\"labels\"]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, all_predictions.numpy())\n",
        "\n",
        "label_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "# Display the matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.pdf')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
